{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from scripts.analyse_pwc_entity_results import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwc_df = load_pwc_full_text('../')\n",
    "pwc_grouped = pwc_df.groupby('s2_paper_id')[['dataset', 'task', 'model_name', 'metric']].aggregate(lambda x : list(set(tuple(x)))).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "314630it [00:56, 5570.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314630 314630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 314630/314630 [02:11<00:00, 2397.64it/s]\n"
     ]
    }
   ],
   "source": [
    "pwc_sentences = load_pwc_sentence_predictions('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwc_sentences['n_ent'] = pwc_sentences[used_entities].applymap(lambda x : len(x)).sum(axis=1)\n",
    "pwc_sentences = pwc_sentences.merge(pwc_grouped, left_on='doc_id', right_on='s2_paper_id')\n",
    "pwc_sentences = pwc_sentences.sort_values(by=['doc_id', 'section_id', 'para_id', 'sentence_id']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def generate_folders_for_documents(BRAT_ANNO_FOLDER) :\n",
    "    for index, row in tqdm(pwc_grouped.iterrows()) :\n",
    "        os.makedirs(BRAT_ANNO_FOLDER + row['s2_paper_id'], exist_ok=True)\n",
    "        annotation_config = '[entities]\\n' + '\\n'.join(used_entities) + '\\n\\n'\n",
    "        annotation_config += '[attributes]\\n'\n",
    "        visual_config = '[labels]\\n'\n",
    "        for k, v in map_true_entity_to_available.items() :\n",
    "            annotation_config += \"\\n\".join([re.sub(r'[^\\w-]', '_', x) + '\\tArg:' + v for x in row[k]]) + '\\n'\n",
    "            visual_config += '\\n'.join([re.sub(r'[^\\w-]', '_', x) + ' | ' + x for x in row[k]]) + '\\n'\n",
    "\n",
    "        annotation_config += '\\n' + open('../scripts/brat_configs/relations.conf').read()\n",
    "        f = open(BRAT_ANNO_FOLDER + row['s2_paper_id'] + '/annotation.conf', 'w')\n",
    "        f.write(annotation_config)\n",
    "        f.close()\n",
    "\n",
    "        visual_config += '\\n' + open('../scripts/brat_configs/drawing.conf').read()\n",
    "        f = open(BRAT_ANNO_FOLDER + row['s2_paper_id'] + '/visual.conf', 'w')\n",
    "        f.write(visual_config)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rows_to_files(df, txt_file, ann_file) :\n",
    "    text = ''\n",
    "    ent_id = 1\n",
    "    start = 0\n",
    "    att_id = 1\n",
    "    for index, row in df.iterrows():\n",
    "        words = row['words'] + ['\\n']\n",
    "        tokens = []\n",
    "\n",
    "        for tok in words :\n",
    "            tokens.append({\n",
    "                'start' : start,\n",
    "                'end' : start + len(tok),\n",
    "                'text' : tok\n",
    "            })\n",
    "            start += len(tok) + 1\n",
    "            text += tok + ' '\n",
    "\n",
    "        for enttype in used_entities :\n",
    "            for tok_start, tok_end, _ in row[enttype] :\n",
    "                ann_file.write('T' + str(ent_id) + '\\t')\n",
    "                ann_file.write(enttype + ' ' + str(tokens[tok_start]['start']) + ' ' + str(tokens[tok_end - 1]['end']) + '\\t')\n",
    "                ann_file.write(text[tokens[tok_start]['start']:tokens[tok_end - 1]['end']] + '\\n')\n",
    "                \n",
    "                matched_true_entities = match_entity_with_best_truth(enttype, \n",
    "                                                                     text[tokens[tok_start]['start']:tokens[tok_end - 1]['end']],\n",
    "                                                                     row[map_available_entity_to_true[enttype]])\n",
    "                for match in matched_true_entities :\n",
    "                    ann_file.write('A' + str(att_id) + '\\t')\n",
    "                    ann_file.write(re.sub(r'[^\\w-]', '_', match) + ' T' + str(ent_id) + '\\n')\n",
    "                    att_id += 1\n",
    "                ent_id += 1\n",
    "\n",
    "    txt_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1171it [00:03, 322.90it/s]\n",
      "100%|██████████| 1170/1170 [01:47<00:00, 10.92it/s]\n"
     ]
    }
   ],
   "source": [
    "BRAT_ANNO_FOLDER_DOCLEVEL = '../brat-v1.3_Crunchy_Frog/data/result_extraction/outputs/brat_annotation_folder_doclevel_original/'\n",
    "pwc_sentences_grouped = pwc_sentences.groupby('doc_id')\n",
    "generate_folders_for_documents(BRAT_ANNO_FOLDER_DOCLEVEL)\n",
    "already_done = []\n",
    "for grp_name, df_group in tqdm(pwc_sentences_grouped) :\n",
    "    if grp_name not in already_done :\n",
    "        filename = BRAT_ANNO_FOLDER_DOCLEVEL + grp_name + '/document'\n",
    "        txt_file, ann_file = open(filename + '.txt', 'w'), open(filename + '.ann', 'w')\n",
    "        add_rows_to_files(df_group, txt_file, ann_file)\n",
    "        txt_file.close()\n",
    "        ann_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
