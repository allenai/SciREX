{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dygie.data.dataset_readers.pwc_json import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PwCJsonReader(max_span_width=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "instances = list(reader.read(\"../data/pwc_split_on_labeled/train.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "instances = [json.loads(s) for s in open('../data/pwc_split_on_labeled/train.jsonl')]\n",
    "# instances += [json.loads(s) for s in open('../data/pwc_split_on_labeled/dev.jsonl')]\n",
    "# instances += [json.loads(s) for s in open('../data/pwc_split_on_labeled/test.jsonl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.analyse_pwc_entity_results import *\n",
    "from collections import defaultdict\n",
    "distances = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dygie.data.dataset_readers.span_utils import *\n",
    "from allennlp.data.dataset_readers.dataset_utils import bioul_tags_to_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ins in instances :\n",
    "    entities = [tuple(x) for x in ins['ner']]\n",
    "    new_entities = [(x[1][0], x[1][1]+1, x[0]) for x in bioul_tags_to_spans(spans_to_bio_tags(entities, len(ins['words'])))]\n",
    "    print(spans_to_bio_tags(entities, len(ins['words'])))\n",
    "    break\n",
    "    assert sorted(entities) == sorted(new_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ins in instances:\n",
    "    for rel in ins[\"n_ary_relations\"]:\n",
    "        rel = Relation(*rel)._asdict()\n",
    "        for r1, r2 in binary_relations:\n",
    "            rel_r1, rel_r2 = rel[r1], rel[r2]\n",
    "            spans_r1 = ins[\"coref\"].get(rel_r1, [])\n",
    "            spans_r2 = ins[\"coref\"].get(rel_r2, [])\n",
    "\n",
    "            if len(spans_r1) == 0 or len(spans_r2) == 0:\n",
    "                continue\n",
    "            distances.append(\n",
    "                {\n",
    "                    \"rel\": (r1, r2),\n",
    "                    \"dist\": min([abs((s1[0] + s1[1]) / 2 - (s2[0] + s2[1]) / 2) for s1 in spans_r1 for s2 in spans_r2]),\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(x='rel', y='dist', data=df)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances[0]['n_ary_relations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.analyse_pwc_entity_results import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline.relation_baseline import compute_metrics, generate_relations\n",
    "a, b, c , d, e = compute_metrics(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['precision_all'] = results['match_all'] / results['pred_all']\n",
    "results['recall_all'] = results['match_all'] / results['true']\n",
    "results['f1_all'] = (2*results['precision_all']*results['recall_all']) / (results['precision_all'] + results['recall_all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(results['n_ent'], results['precision_all'])\n",
    "sns.regplot(results['n_ent'], results['recall_all'])\n",
    "# sns.regplot(results['n_ent'], results['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckresults['precision_head'] = results['match_head'] / results['pred_head']\n",
    "results['recall_head'] = results['match_head'] / results['true']\n",
    "results['f1_head'] = (2*results['precision_head']*results['recall_head']) / (results['precision_head'] + results['recall_head'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(results['n_ent'], results['precision_head'])\n",
    "sns.regplot(results['n_ent'], results['recall_head'])\n",
    "# sns.regplot(results['n_ent'], results['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch = []\n",
    "n_waste = []\n",
    "for n in range(6, 7) :\n",
    "    s = 3\n",
    "    pairs = sorted(list(set([(i, j) for i in range(n) for j in range(i+1, n)])))\n",
    "\n",
    "    pairs_done = []\n",
    "    elem_done = {k:set([k]) for k in range(n)}\n",
    "    batches = []\n",
    "\n",
    "    def get_first_incomplete_element(elem_done, elist) :\n",
    "        elist = set(elist)\n",
    "        insec = [(k, len(elist & v), len(v)) for k, v in elem_done.items() if k not in elist and len(elem_done[k]) < n]\n",
    "        insec = sorted(insec, key=lambda x : (x[1], x[2]))\n",
    "        return insec[0][0]if len(insec) > 0 else -1\n",
    "\n",
    "    from itertools import combinations\n",
    "\n",
    "    waste = 0\n",
    "    while len(set(pairs_done)) < len(pairs) :\n",
    "        batch = []\n",
    "        celem = []\n",
    "        for i in range(s) :\n",
    "            not_done = get_first_incomplete_element(elem_done, celem)\n",
    "            if not_done != -1 :\n",
    "                batch.append(not_done)\n",
    "                celem.append(not_done)\n",
    "\n",
    "        batch = sorted(batch)\n",
    "        for i in range(len(batch)) :\n",
    "            for j in set(range(len(batch))) - set([i]) :\n",
    "                elem_done[batch[i]].add(batch[j])\n",
    "\n",
    "        batches.append(batch)\n",
    "        for a, b in combinations(range(len(batch)), 2) :\n",
    "            x = (batch[a], batch[b])\n",
    "            if x not in pairs_done :\n",
    "                pairs_done.append(x)\n",
    "            else :\n",
    "                waste += 1\n",
    "        print(batch, waste, pairs_done)\n",
    "    \n",
    "    n_batch.append(len(batches))\n",
    "    n_waste.append(waste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
