{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.convert_brat_annotations_to_json import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from baseline.baseline import *\n",
    "from scripts.analyse_pwc_entity_results import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "314630it [01:07, 4643.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314630 314630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 314630/314630 [00:16<00:00, 18748.10it/s]\n",
      "  5%|▍         | 53/1172 [00:00<00:21, 52.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../brat/data/result_extraction/outputs/brat_annotation_folder_doclevel/.stats_cache  have not document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 681/1172 [00:06<00:05, 93.67it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute before Trigger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 908/1172 [00:08<00:01, 155.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute before Trigger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1082/1172 [00:09<00:00, 192.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute before Trigger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1124/1172 [00:09<00:00, 198.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../brat/data/result_extraction/outputs/brat_annotation_folder_doclevel/not_found  have not document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1172/1172 [00:10<00:00, 116.24it/s]\n",
      "  8%|▊         | 92/1172 [00:02<00:19, 56.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../brat/data/result_extraction/outputs/brat_annotation_folder_doclevel_original/.stats_cache  have not document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1075/1172 [00:11<00:00, 153.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute before Trigger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1172/1172 [00:12<00:00, 96.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../brat/data/result_extraction/outputs/brat_annotation_folder_doclevel_original/not_found  have not document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 314630/314630 [00:14<00:00, 22114.41it/s]\n",
      "100%|██████████| 314630/314630 [00:20<00:00, 15191.57it/s]\n",
      "100%|██████████| 1170/1170 [00:00<00:00, 54126.62it/s]\n",
      "100%|██████████| 314630/314630 [00:20<00:00, 15279.61it/s]\n",
      "100%|██████████| 1170/1170 [00:03<00:00, 351.36it/s]\n",
      "100%|██████████| 1170/1170 [00:03<00:00, 356.26it/s]\n"
     ]
    }
   ],
   "source": [
    "df_concat = combine_brat_to_original_data('../data/pwc_s2_cleaned_text_v2.jsonl',\n",
    "                                         '../data/pwc_s2_cleaned_text_v2_sentences.jsonl',\n",
    "                                         '../outputs/pwc_s2_cleaned_text_v2_sentences_predictions.jsonl',\n",
    "                                         '../brat/data/result_extraction/outputs/brat_annotation_folder_doclevel_original/',\n",
    "                                         '../brat/data/result_extraction/outputs/brat_annotation_folder_doclevel/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dygie.data.dataset_readers.read_pwc_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1170/1170 [00:41<00:00, 28.08it/s]\n"
     ]
    }
   ],
   "source": [
    "data = read_dataframe(df_concat)\n",
    "dump_to_file(data, '../data/pwc_split_on_labeled', max_id='0e37c8f19eefeb0c20d92f5cb4df4153077c116b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_concat[df_concat.clean_type != 'normal'].groupby(['doc_id', 'para_num'])['words']\\\n",
    "                        .apply(lambda x : sum([len(w) for w in x]))\\\n",
    "                        .describe(percentiles=[0.5, 0.75, 0.9, 0.99])).transpose()\n",
    "print(tabulate(df.values, headers=df.columns, tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.groupby('doc_id')['words']\\\n",
    ".agg(lambda x : \"our system\" in \" \".join([w.lower() for y in x for w in y])).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics \n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_done = df_concat[df_concat.doc_id < '0e37c8f19eefeb0c20d92f5cb4df4153077c116b']\n",
    "print(len(df_done.doc_id.unique()))\n",
    "n_spans_entity = sum([x['type_change'] for x in list(df_done['stats']) if x is not None])\n",
    "n_spans_attr = sum([x['change_attributes'] for x in list(df_done['stats']) if x is not None])\n",
    "n_spans_kept = sum([x['spans_kept'] for x in list(df_done['stats']) if x is not None])\n",
    "n_spans_old = sum([x['old_spans'] for x in list(df_done['stats']) if x is not None])\n",
    "print(n_spans_entity, n_spans_attr, n_spans_kept, n_spans_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linked_entities_from_span(spans) :\n",
    "    index_map = {k:set() for k in used_entities}\n",
    "    for span in spans :\n",
    "        if len(span.links) > 0 :\n",
    "            index_map[span.entity] |= span.links\n",
    "    return index_map\n",
    "            \n",
    "df_done = df_concat[df_concat.doc_id < '0e37c8f19eefeb0c20d92f5cb4df4153077c116b']\n",
    "linked_entities = df_done['entities'].progress_apply(get_linked_entities_from_span)\n",
    "df_linked = pd.concat([df_done, pd.DataFrame.from_records(linked_entities)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_elist = df_linked.groupby('doc_id')[[k + '_Rel' for k in used_entities]].agg(lambda x : set(x.iloc[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_elist = df_linked.groupby('doc_id')[used_entities].agg(lambda x : set.union(*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "axes = [x for y in axes for x in y]\n",
    "for i, e in enumerate(used_entities) :\n",
    "    true_ent = true_elist[e + '_Rel']\n",
    "    pred_ent = ann_elist[e]\n",
    "    nent = [len(x - y) for x, y in zip(true_ent, pred_ent)]\n",
    "    sns.countplot(nent, ax=axes[i])\n",
    "    axes[i].set_title(e)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_aggregating_function = {t:lambda x : set().union(*x) for t in used_entities}\n",
    "para_aggregating_function.update({'Relations':lambda x : x.values[-1]})\n",
    "df_linked_para = df_linked.groupby(['doc_id', 'para_num'])[used_entities + ['Relations']].agg(para_aggregating_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, product\n",
    "binary_relations = list(combinations(used_entities, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_list_of_binary_relations(rels) :\n",
    "    index_map = {k:[] for k in binary_relations}\n",
    "    for r in rels :\n",
    "        r = r._asdict()\n",
    "        for k in binary_relations :\n",
    "            index_map[k].append((r[k[0]], r[k[1]]))\n",
    "            \n",
    "    return {k:set(v) for k, v in index_map.items()}\n",
    "\n",
    "df_linked_para['binary_relations_true'] = df_linked_para['Relations'].progress_apply(lambda x : generate_list_of_binary_relations(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relation_para_mapping(rows) :\n",
    "    true_relations = rows['binary_relations_true'].values[-1]\n",
    "    relation_paras = {k:{x:0 for x in list(v)} for k, v in true_relations.items()}\n",
    "    for index, row in rows.iterrows() :\n",
    "        for r1, r2 in binary_relations :\n",
    "            rels = product(row[r1], row[r2])\n",
    "            for r in rels :\n",
    "                if r in relation_paras[(r1, r2)] :\n",
    "                    relation_paras[(r1, r2)][r] += 1\n",
    "    return relation_paras\n",
    "                \n",
    "df_linked_para_stats = df_linked_para.groupby('doc_id').progress_apply(get_relation_para_mapping)\n",
    "df_linked_para_stats = df_linked_para_stats.apply(lambda x : pd.Series({\"-\".join(k):v for k, v in x.items()}))\n",
    "fig, axes = plt.subplots(3, 2, figsize=(10, 10))\n",
    "axes = [x for y in axes for x in y]\n",
    "df_linked_para_stats_done = df_linked_para_stats[df_linked_para_stats.index < '0e37c8f19eefeb0c20d92f5cb4df4153077c116b']\n",
    "for i, r in enumerate(binary_relations) :\n",
    "    sns.countplot(df_linked_para_stats_done.applymap(lambda x : list(x.values()))\\\n",
    "                  .apply(lambda x : [v for y in x for v in y])['-'.join(r)], ax=axes[i])\n",
    "    axes[i].set_title(r)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linked['linked_spans'] = df_linked['entities'].apply(lambda cluster : sum([len(x.links) > 0 for x in cluster]))\n",
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "for n in range(2) :\n",
    "    stats = (df_linked.groupby(['doc_id', 'para_num'])['linked_spans'].sum() > n).reset_index()\\\n",
    "                      .groupby(['doc_id'])['linked_spans'].agg([('linked', 'sum'), ('total', len)])\n",
    "\n",
    "    sns.regplot(x='total', y='linked', data=stats[stats.index < '0e37c8f19eefeb0c20d92f5cb4df4153077c116b'], label=n, scatter_kws={'s' : 5})\n",
    "    plt.legend(title=\"n\")\n",
    "    plt.xlabel(\"Total #paragraphs\")\n",
    "    plt.ylabel(\"#paragraphs with $>n$ linked entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relation_para_mapping(row) :\n",
    "    true_relations = row['binary_relations_true']\n",
    "    contain_rel = 0\n",
    "    for r1, r2 in binary_relations :\n",
    "        rels = product(row[r1], row[r2])\n",
    "        for r in rels :\n",
    "            if r in true_relations[(r1, r2)] :\n",
    "                contain_rel += 1\n",
    "    return contain_rel\n",
    "                \n",
    "df_num_rel_para_stats = df_linked_para.progress_apply(get_relation_para_mapping, axis=1)\n",
    "stats = df_num_rel_para_stats.reset_index().groupby(['doc_id'])[0].agg([('linked', lambda x: sum([y>0 for y in x])), ('total', len)])\n",
    "\n",
    "sns.lmplot(x='total', y='linked', data=stats[stats.index < '0e37c8f19eefeb0c20d92f5cb4df4153077c116b'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def count_and_clip(sets) :\n",
    "    c = sum([Counter(x) for x in sets], Counter())\n",
    "    c = Counter({k:(1 if v > 0 else 0) for k, v in c.items()})\n",
    "    return [c]\n",
    "\n",
    "def para_with_one_entity(counters) :\n",
    "    c = counters[0]\n",
    "    return sum([v <= 1 for k, v in c.items()])\n",
    "\n",
    "para_counts = df_linked.groupby(['doc_id', 'section_id', 'para_id'])['Material'].progress_apply(count_and_clip)\n",
    "stats = para_counts.groupby('doc_id').agg([('counts', lambda x : para_with_one_entity([sum([w[0] for w in x], Counter())]))\n",
    "                                                    , ('total', len)])\n",
    "\n",
    "sns.lmplot(x='total', y='counts', data=stats[stats.index < '07cca2bdd0dc2fee02889e17789748eba9d06ffa'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in enttypes :\n",
    "    df_done = df_linked[df_linked.doc_id < '09da677bdbba113374d8fe4bb15ecfbdb4c8fe40']\n",
    "    true_ent = df_done.groupby(['doc_id'])[t + '_Rel'].apply(lambda x: set.union(*[set(w.keys()) for w in x]))\n",
    "    ann_links = df_done.groupby(['doc_id'])[t].apply(lambda x : set.union(*list(x)))\n",
    "    link_sets = pd.concat([true_ent, ann_links], axis=1)\n",
    "    \n",
    "    print(t, sum([len(x - y) > 0 for x, y in zip(true_ent, ann_links)]), sum([len(y - x) > 0 for x, y in zip(true_ent, ann_links)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document Statistics\n",
    "==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_concat.groupby('doc_id')['words']\\\n",
    "                        .apply(lambda x : sum([len(w) for w in x]))\\\n",
    "                        .describe(percentiles=[0.5, 0.75, 0.9, 0.99])).transpose()\n",
    "print(tabulate(df.values, headers=df.columns, tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_concat.groupby('doc_id')['sentence']\\\n",
    "                        .apply(lambda x : sum([len(w) for w in x]))\\\n",
    "                        .describe(percentiles=[0.5, 0.75, 0.9, 0.99])).transpose()\n",
    "print(tabulate(df.values, headers=df.columns, tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_concat.groupby(['doc_id', 'para_num'])['words']\\\n",
    "                        .apply(lambda x : sum([len(w) for w in x]))\\\n",
    "                        .describe(percentiles=[0.5, 0.75, 0.9, 0.99])).transpose()\n",
    "print(tabulate(df.values, headers=df.columns, tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_concat.groupby(['doc_id'])['para_num'].agg(lambda x: max(x) + 1)\\\n",
    "                        .describe(percentiles=[0.5, 0.75, 0.9, 0.99])).transpose()\n",
    "print(tabulate(df.values, headers=df.columns, tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.linregress(para_features.groupby('doc_id')['entities'].agg(len), para_features.groupby('doc_id')['entities'].agg(sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
